{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport spacy\n\n\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split\n\n\nfrom keras.preprocessing.text import Tokenizer \nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras import backend as K \nimport gensim\n\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:11:39.329304Z","iopub.execute_input":"2022-05-13T12:11:39.329729Z","iopub.status.idle":"2022-05-13T12:11:39.336085Z","shell.execute_reply.started":"2022-05-13T12:11:39.329651Z","shell.execute_reply":"2022-05-13T12:11:39.335252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T11:23:58.767123Z","iopub.execute_input":"2022-05-13T11:23:58.767459Z","iopub.status.idle":"2022-05-13T11:23:59.034388Z","shell.execute_reply.started":"2022-05-13T11:23:58.767393Z","shell.execute_reply":"2022-05-13T11:23:59.033622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/news-summary/news_summary.csv', encoding='latin-1')\nmore_df = pd.read_csv('/kaggle/input/news-summary/news_summary_more.csv', encoding='latin-1')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-05-13T11:24:09.711475Z","iopub.execute_input":"2022-05-13T11:24:09.711762Z","iopub.status.idle":"2022-05-13T11:24:10.660081Z","shell.execute_reply.started":"2022-05-13T11:24:09.711711Z","shell.execute_reply":"2022-05-13T11:24:10.659338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_df = pd.concat([df, more_df], axis=0).reset_index(drop=True)\nconcat_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:24:12.062491Z","iopub.execute_input":"2022-05-13T11:24:12.063073Z","iopub.status.idle":"2022-05-13T11:24:12.163041Z","shell.execute_reply.started":"2022-05-13T11:24:12.062822Z","shell.execute_reply":"2022-05-13T11:24:12.162202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:24:14.429281Z","iopub.execute_input":"2022-05-13T11:24:14.429592Z","iopub.status.idle":"2022-05-13T11:24:14.452066Z","shell.execute_reply.started":"2022-05-13T11:24:14.429538Z","shell.execute_reply":"2022-05-13T11:24:14.451269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_df['headlines'] = concat_df.headlines.apply(lambda x: x.lower())\nconcat_df['text'] = concat_df.text.apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:24:17.284370Z","iopub.execute_input":"2022-05-13T11:24:17.284999Z","iopub.status.idle":"2022-05-13T11:24:17.483551Z","shell.execute_reply.started":"2022-05-13T11:24:17.284692Z","shell.execute_reply":"2022-05-13T11:24:17.482804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install text_hammer\nimport  text_hammer as th","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:24:19.048435Z","iopub.execute_input":"2022-05-13T11:24:19.048737Z","iopub.status.idle":"2022-05-13T11:24:27.772852Z","shell.execute_reply.started":"2022-05-13T11:24:19.048683Z","shell.execute_reply":"2022-05-13T11:24:27.772067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(df, column):\n    column = column\n    df[column] = df[column].progress_apply(lambda x: re.sub('\"',\"'\", x))\n    df[column] = df[column].progress_apply(lambda x:th.remove_special_chars(x))\n    df[column] = df[column].progress_apply(lambda x:th.remove_html_tags(x))\n    df[column] = df[column].progress_apply(lambda x: th.remove_urls(x))\n    df[column] = df[column].progress_apply(lambda x:th.cont_exp(x))\n    df[column] = df[column].progress_apply(lambda x: re.sub('[^a-zA-Z]+',' ', x))\n    df[column] = df[column].progress_apply(lambda x:' '.join([x for x in x.split() if len(x)>=2]) )\n    return df[column]","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:24:27.775157Z","iopub.execute_input":"2022-05-13T11:24:27.775673Z","iopub.status.idle":"2022-05-13T11:24:27.785412Z","shell.execute_reply.started":"2022-05-13T11:24:27.775618Z","shell.execute_reply":"2022-05-13T11:24:27.784758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_headlines = clean_text(concat_df, 'headlines')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:24:33.371514Z","iopub.execute_input":"2022-05-13T11:24:33.371847Z","iopub.status.idle":"2022-05-13T11:27:18.749976Z","shell.execute_reply.started":"2022-05-13T11:24:33.371779Z","shell.execute_reply":"2022-05-13T11:27:18.748901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_text = clean_text(concat_df, 'text')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:27:18.752329Z","iopub.execute_input":"2022-05-13T11:27:18.752780Z","iopub.status.idle":"2022-05-13T11:35:34.275479Z","shell.execute_reply.started":"2022-05-13T11:27:18.752731Z","shell.execute_reply":"2022-05-13T11:35:34.274676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en', disable=['ner', 'parser']) \ndocs = nlp.pipe(processed_text, batch_size=5000, n_threads=-1)\ntext = [str(doc) for doc in docs]","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-13T11:35:34.276816Z","iopub.execute_input":"2022-05-13T11:35:34.277288Z","iopub.status.idle":"2022-05-13T11:41:32.653888Z","shell.execute_reply.started":"2022-05-13T11:35:34.277236Z","shell.execute_reply":"2022-05-13T11:41:32.653175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docs = nlp.pipe(processed_headlines, batch_size=5000, n_threads=-1)\nheadlines = ['_START_ '+ str(doc) + ' _END_' for doc in docs]","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:41:32.655204Z","iopub.execute_input":"2022-05-13T11:41:32.655513Z","iopub.status.idle":"2022-05-13T11:43:44.829572Z","shell.execute_reply.started":"2022-05-13T11:41:32.655468Z","shell.execute_reply":"2022-05-13T11:43:44.828513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_df['text'] = pd.Series(text)\nconcat_df['headlines'] = pd.Series(headlines)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:43:44.831490Z","iopub.execute_input":"2022-05-13T11:43:44.831778Z","iopub.status.idle":"2022-05-13T11:43:44.900600Z","shell.execute_reply.started":"2022-05-13T11:43:44.831733Z","shell.execute_reply":"2022-05-13T11:43:44.899930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_text_len = 0\n\nfor i in concat_df['text']:\n    tmp = len(i.split())\n    if(tmp > max_text_len):\n        max_text_len = tmp\n       \nprint(max_text_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:43:44.902927Z","iopub.execute_input":"2022-05-13T11:43:44.903354Z","iopub.status.idle":"2022-05-13T11:43:45.298078Z","shell.execute_reply.started":"2022-05-13T11:43:44.903305Z","shell.execute_reply":"2022-05-13T11:43:45.297246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_headlines_len = 0\n\nfor i in concat_df['headlines']:\n    tmp = len(i.split())\n    if(tmp > max_headlines_len):\n        max_headlines_len = tmp\n\nprint(max_headlines_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:46:19.580897Z","iopub.execute_input":"2022-05-13T11:46:19.581217Z","iopub.status.idle":"2022-05-13T11:46:19.704022Z","shell.execute_reply.started":"2022-05-13T11:46:19.581163Z","shell.execute_reply":"2022-05-13T11:46:19.703154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_text_len = 60\nmax_headlines_len = 15","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:47:31.357323Z","iopub.execute_input":"2022-05-13T11:47:31.357649Z","iopub.status.idle":"2022-05-13T11:47:31.361789Z","shell.execute_reply.started":"2022-05-13T11:47:31.357595Z","shell.execute_reply":"2022-05-13T11:47:31.360707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = np.array(concat_df['text'])\nheadlines = np.array(concat_df['headlines'])\n\ntmp_txt = []\ntmp_hln = []\n\nfor  i in range(len(text)):\n    if(len(headlines[i].split()) <= max_headlines_len and len(text[i].split()) <= max_text_len):\n        tmp_txt.append(text[i])\n        tmp_hln.append(headlines[i])\n        \ntrimmed_df = pd.DataFrame({'text':tmp_txt, 'headlines':tmp_hln})","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:52:32.986684Z","iopub.execute_input":"2022-05-13T11:52:32.987038Z","iopub.status.idle":"2022-05-13T11:52:33.594501Z","shell.execute_reply.started":"2022-05-13T11:52:32.986984Z","shell.execute_reply":"2022-05-13T11:52:33.593716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trimmed_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:52:45.948579Z","iopub.execute_input":"2022-05-13T11:52:45.949038Z","iopub.status.idle":"2022-05-13T11:52:45.958183Z","shell.execute_reply.started":"2022-05-13T11:52:45.948817Z","shell.execute_reply":"2022-05-13T11:52:45.957435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trimmed_df['headlines'] = trimmed_df['headlines'].apply(lambda x : 'sostok '+ x + ' eostok')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:53:54.978931Z","iopub.execute_input":"2022-05-13T11:53:54.979232Z","iopub.status.idle":"2022-05-13T11:53:55.039516Z","shell.execute_reply.started":"2022-05-13T11:53:54.979181Z","shell.execute_reply":"2022-05-13T11:53:55.038852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trimmed_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:54:03.938183Z","iopub.execute_input":"2022-05-13T11:54:03.938472Z","iopub.status.idle":"2022-05-13T11:54:03.949298Z","shell.execute_reply.started":"2022-05-13T11:54:03.938423Z","shell.execute_reply":"2022-05-13T11:54:03.947892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SEQ2SEQ MODEL BUILDING **","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(np.array(trimmed_df['text']),np.array(trimmed_df['headlines']),test_size=0.2,random_state=0,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:07:22.939700Z","iopub.execute_input":"2022-05-13T12:07:22.940256Z","iopub.status.idle":"2022-05-13T12:07:22.985304Z","shell.execute_reply.started":"2022-05-13T12:07:22.940002Z","shell.execute_reply":"2022-05-13T12:07:22.984482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tokenizer = Tokenizer() \nx_tokenizer.fit_on_texts(list(x_train))\nprint(1+len(x_tokenizer.word_index))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:07:27.721908Z","iopub.execute_input":"2022-05-13T12:07:27.722198Z","iopub.status.idle":"2022-05-13T12:07:32.672623Z","shell.execute_reply.started":"2022-05-13T12:07:27.722147Z","shell.execute_reply":"2022-05-13T12:07:32.671721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"limit = 3\ncount = 0\nfreq  = 0\n\nfor key, value in x_tokenizer.word_counts.items():\n    if(value < limit):\n        count = count + 1\n        freq = freq + value\n        \nprint(\"count: \", count)\nprint(\"freq: \",freq)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:07:32.674545Z","iopub.execute_input":"2022-05-13T12:07:32.675075Z","iopub.status.idle":"2022-05-13T12:07:32.729717Z","shell.execute_reply.started":"2022-05-13T12:07:32.675018Z","shell.execute_reply":"2022-05-13T12:07:32.728820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prepare a tokenizer for reviews on training data\nx_tokenizer = Tokenizer(num_words=40000) \nx_tokenizer.fit_on_texts(list(x_train))\n\n#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\nx_train_seq    =   x_tokenizer.texts_to_sequences(x_train) \nx_test_seq   =   x_tokenizer.texts_to_sequences(x_test)\n\n#padding zero upto maximum length\nx_train    =   pad_sequences(x_train_seq,  maxlen=max_text_len, padding='post')\nx_test   =   pad_sequences(x_test_seq, maxlen=max_text_len, padding='post')\n\n#size of vocabulary ( +1 for padding token)\nx_voc   =  x_tokenizer.num_words + 1\n\nprint(\"Size of vocabulary: \",x_voc)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:07:32.731267Z","iopub.execute_input":"2022-05-13T12:07:32.731985Z","iopub.status.idle":"2022-05-13T12:07:44.188153Z","shell.execute_reply.started":"2022-05-13T12:07:32.731880Z","shell.execute_reply":"2022-05-13T12:07:44.187221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_tokenizer = Tokenizer()   \ny_tokenizer.fit_on_texts(list(y_train))\nprint(1+len(y_tokenizer.word_index))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:07:44.192887Z","iopub.execute_input":"2022-05-13T12:07:44.195065Z","iopub.status.idle":"2022-05-13T12:07:46.132146Z","shell.execute_reply.started":"2022-05-13T12:07:44.195012Z","shell.execute_reply":"2022-05-13T12:07:46.131409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"limit = 3\ncount = 0\nfreq  = 0\n\nfor key, value in y_tokenizer.word_counts.items():\n    if(value < limit):\n        count = count + 1\n        freq = freq + value\n        \nprint(\"count: \", count)\nprint(\"freq: \",freq)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:07:46.133638Z","iopub.execute_input":"2022-05-13T12:07:46.133938Z","iopub.status.idle":"2022-05-13T12:07:46.152744Z","shell.execute_reply.started":"2022-05-13T12:07:46.133889Z","shell.execute_reply":"2022-05-13T12:07:46.151655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prepare a tokenizer for reviews on training data\ny_tokenizer = Tokenizer(num_words=20000) \ny_tokenizer.fit_on_texts(list(y_train))\n\n#convert text sequences into integer sequences (i.e one hot encode the text in Y)\ny_train_seq    =   y_tokenizer.texts_to_sequences(y_train) \ny_test_seq   =   y_tokenizer.texts_to_sequences(y_test) \n\n#padding zero upto maximum length\ny_train    =   pad_sequences(y_train_seq, maxlen=max_headlines_len, padding='post')\ny_test  =   pad_sequences(y_test_seq, maxlen=max_headlines_len, padding='post')\n\n#size of vocabulary\ny_voc  =   y_tokenizer.num_words +1\nprint(\"Size of vocabulary: \", y_voc)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:08:05.698070Z","iopub.execute_input":"2022-05-13T12:08:05.698366Z","iopub.status.idle":"2022-05-13T12:08:10.787327Z","shell.execute_reply.started":"2022-05-13T12:08:05.698314Z","shell.execute_reply":"2022-05-13T12:08:10.786609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n\nlatent_dim = 300\nembedding_dim=200\n\n# Encoder\nencoder_inputs = Input(shape=(max_text_len,))\n\n#embedding layer\nenc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n\n#encoder lstm 1\nencoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n\n#encoder lstm 2\nencoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n\n#encoder lstm 3\nencoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\nencoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\n\n#embedding layer\ndec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\ndecoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n\n#dense layer\ndecoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model \nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:11:47.967237Z","iopub.execute_input":"2022-05-13T12:11:47.967534Z","iopub.status.idle":"2022-05-13T12:11:49.565137Z","shell.execute_reply.started":"2022-05-13T12:11:47.967482Z","shell.execute_reply":"2022-05-13T12:11:49.563566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:11:56.261857Z","iopub.execute_input":"2022-05-13T12:11:56.262179Z","iopub.status.idle":"2022-05-13T12:11:56.315967Z","shell.execute_reply.started":"2022-05-13T12:11:56.262127Z","shell.execute_reply":"2022-05-13T12:11:56.315226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:11:58.817405Z","iopub.execute_input":"2022-05-13T12:11:58.817708Z","iopub.status.idle":"2022-05-13T12:11:58.822159Z","shell.execute_reply.started":"2022-05-13T12:11:58.817656Z","shell.execute_reply":"2022-05-13T12:11:58.821233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Start fitting the model with the data**","metadata":{}},{"cell_type":"code","source":"history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:15:20.555272Z","iopub.execute_input":"2022-05-13T12:15:20.555584Z","iopub.status.idle":"2022-05-13T12:55:25.240275Z","shell.execute_reply.started":"2022-05-13T12:15:20.555530Z","shell.execute_reply":"2022-05-13T12:55:25.239387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize the model learning**","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:56:30.653286Z","iopub.execute_input":"2022-05-13T12:56:30.653596Z","iopub.status.idle":"2022-05-13T12:56:30.818533Z","shell.execute_reply.started":"2022-05-13T12:56:30.653542Z","shell.execute_reply":"2022-05-13T12:56:30.817876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Next, letâ€™s build the dictionary to convert the index to word for target and source vocabulary:**","metadata":{}},{"cell_type":"code","source":"reverse_target_word_index=y_tokenizer.index_word\nreverse_source_word_index=x_tokenizer.index_word\ntarget_word_index=y_tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:56:37.232265Z","iopub.execute_input":"2022-05-13T12:56:37.232754Z","iopub.status.idle":"2022-05-13T12:56:37.237128Z","shell.execute_reply.started":"2022-05-13T12:56:37.232682Z","shell.execute_reply":"2022-05-13T12:56:37.236197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode the input sequence to get the feature vector\nencoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n\n# Get the embeddings of the decoder sequence\ndec_emb2= dec_emb_layer(decoder_inputs) \n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\n# A dense softmax layer to generate prob dist. over the target vocabulary\ndecoder_outputs2 = decoder_dense(decoder_outputs2) \n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:56:40.923961Z","iopub.execute_input":"2022-05-13T12:56:40.924257Z","iopub.status.idle":"2022-05-13T12:56:41.382260Z","shell.execute_reply.started":"2022-05-13T12:56:40.924205Z","shell.execute_reply":"2022-05-13T12:56:41.381458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We are defining a function below which is the implementation of the inference process**","metadata":{}},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n    \n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    \n    # Populate the first word of target sequence with the start word.\n    target_seq[0, 0] = target_word_index['sostok']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n      \n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_word_index[sampled_token_index]\n        \n        if(sampled_token!='eostok'):\n            decoded_sentence += ' '+sampled_token\n\n        # Exit condition: either hit max length or find stop word.\n        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_headlines_len-1)):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update internal states\n        e_h, e_c = h, c\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:56:45.158179Z","iopub.execute_input":"2022-05-13T12:56:45.158479Z","iopub.status.idle":"2022-05-13T12:56:45.168213Z","shell.execute_reply.started":"2022-05-13T12:56:45.158426Z","shell.execute_reply":"2022-05-13T12:56:45.167386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:**\n","metadata":{}},{"cell_type":"code","source":"def seq2summary(input_seq):\n    newString=''\n    for i in input_seq:\n        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n            newString=newString+reverse_target_word_index[i]+' '\n    return newString\n\ndef seq2text(input_seq):\n    newString=''\n    for i in input_seq:\n        if(i!=0):\n            newString=newString+reverse_source_word_index[i]+' '\n    return newString","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:56:49.814760Z","iopub.execute_input":"2022-05-13T12:56:49.815096Z","iopub.status.idle":"2022-05-13T12:56:49.821989Z","shell.execute_reply.started":"2022-05-13T12:56:49.815043Z","shell.execute_reply":"2022-05-13T12:56:49.821217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Run the model over the data to see the results**","metadata":{}},{"cell_type":"code","source":"print(\"Review: \", seq2text(x_train[0]))\nprint(\"Original summary: \", seq2summary(y_train[0]))\nprint(\"predicted summary: \", decode_sequence(x_train[i].reshape(1,max_text_len)))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:57:04.403660Z","iopub.execute_input":"2022-05-13T12:57:04.403978Z","iopub.status.idle":"2022-05-13T12:57:05.490522Z","shell.execute_reply.started":"2022-05-13T12:57:04.403916Z","shell.execute_reply":"2022-05-13T12:57:05.489591Z"},"trusted":true},"execution_count":null,"outputs":[]}]}